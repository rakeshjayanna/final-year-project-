# ü•≠ Mango Analysis System: AI-Powered Disease & Pesticide Detection

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![React](https://img.shields.io/badge/React-18.2+-61DAFB.svg)](https://reactjs.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.18+-FF6F00.svg)](https://www.tensorflow.org/)
[![Flask](https://img.shields.io/badge/Flask-3.0-black.svg)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A comprehensive full-stack web application for automated mango quality analysis using deep learning and machine learning. This system provides dual-task analysis capabilities with intelligent hybrid model selection for optimal accuracy.

**üéØ Quick Stats:**
- ‚úÖ **81.5% accuracy** on disease detection (5 classes)
- ‚úÖ **97.1% accuracy** on pesticide detection (binary)
- ‚úÖ **Hybrid AI** combining CNN + SVM
- ‚úÖ **Production-ready** React + Flask stack
- ‚úÖ **Real-time predictions** with confidence scores

---

## üìã Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Technology Stack](#-technology-stack)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Model Training](#-model-training)
- [Usage](#-usage)
- [API Documentation](#-api-documentation)
- [Performance Metrics](#-performance-metrics)
- [Screenshots](#-screenshots)
- [Deployment](#-deployment)
- [Troubleshooting](#-troubleshooting)
- [Future Enhancements](#-future-enhancements)
- [Contributing](#-contributing)
- [License](#-license)

---

## üéØ Overview

This intelligent system supports **two distinct analysis tasks**:

### 1. ü¶† Disease Detection (Multi-class Classification)
Classifies mangoes into 5 disease categories:
- **Alternaria** - Fungal disease causing dark spots
- **Anthracnose** - Common fungal infection
- **Black Mould Rot** - Post-harvest decay
- **Healthy** - No disease detected
- **Stem end Rot** - Stem infection

### 2. üß™ Pesticide Detection (Binary Classification)
Determines food safety:
- **Organic** - No pesticide residue detected
- **Pesticide** - Pesticide treatment identified

### How It Works

1. **User uploads** mango image via web interface
2. **Backend processes** image through dual AI models:
   - **CNN** extracts deep visual features
   - **SVM** classifies using CNN features
3. **Hybrid selection** automatically chooses best model
4. **Results displayed** with confidence scores and per-class probabilities

---

## ‚ú® Features

### Core Functionality
‚úÖ **Dual-Task Analysis** - Switch between disease and pesticide detection  
‚úÖ **Hybrid Model Selection** - Auto-selects best performing model (CNN or SVM)  
‚úÖ **Real-time Predictions** - Fast inference (< 2 seconds)  
‚úÖ **Confidence Scores** - Percentage confidence for each prediction  
‚úÖ **Per-Class Probabilities** - Detailed breakdown of all class likelihoods  
‚úÖ **Image Validation** - Rejects non-mango images with low confidence  

### User Experience
üé® **Beautiful UI** - Modern glassmorphism design with Tailwind CSS  
üìä **Interactive Charts** - Model comparison visualizations with Chart.js  
üì± **Responsive Design** - Works on desktop, tablet, and mobile  
üîÑ **Live Status** - Real-time backend health monitoring  
üñºÔ∏è **Drag & Drop** - Easy image upload with preview  
üåà **Smooth Animations** - Polished transitions with Framer Motion  

### Technical Features
üöÄ **RESTful API** - Clean endpoints with proper error handling  
üíæ **Model Caching** - Intelligent memory management  
üìà **Data Augmentation** - Training-time image transformations  
üéØ **Multi-task Architecture** - Independent model artifacts per task  
üîí **Input Validation** - File type, size, and content checks  

---

## üõ† Technology Stack

### Backend Stack (Python)

| Technology | Version | Purpose |
|------------|---------|---------|
| **Flask** | 3.0.0 | Lightweight web framework for REST API |
| **TensorFlow** | 2.18.1 | Deep learning framework for CNN training |
| **Keras** | Built-in | High-level neural network API |
| **Scikit-learn** | 1.3.2 | SVM classifier, preprocessing, metrics |
| **NumPy** | 1.26.2 | Numerical computing and array operations |
| **Pillow (PIL)** | 10.1.0 | Image loading, preprocessing, resizing |
| **Flask-CORS** | 4.0.0 | Cross-Origin Resource Sharing support |
| **Joblib** | 1.3.2 | Model serialization and persistence |
| **Matplotlib** | 3.8.2 | Training curve and metric visualization |
| **Seaborn** | 0.13.0 | Statistical data visualization |
| **Gunicorn** | 21.2.0 | Production WSGI HTTP server |

### Frontend Stack (JavaScript/React)

| Technology | Version | Purpose |
|------------|---------|---------|
| **React** | 18.2.0 | Component-based UI framework |
| **React DOM** | 18.2.0 | React rendering for web |
| **React Router** | 6.26.2 | Client-side routing and navigation |
| **Tailwind CSS** | 3.4.14 | Utility-first CSS framework |
| **Chart.js** | 4.4.4 | Canvas-based chart library |
| **react-chartjs-2** | 5.2.0 | React wrapper for Chart.js |
| **Framer Motion** | 11.3.24 | Animation library for React |
| **PostCSS** | 8.4.47 | CSS transformation tool |
| **Autoprefixer** | 10.4.20 | Vendor prefix automation |

### Development Tools
- **Git** - Version control
- **npm** - Frontend package management
- **pip** - Python package management
- **VS Code** - Recommended IDE with Python and ESLint extensions

---

## üèó Architecture

### System Architecture Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      CLIENT LAYER                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ          React Frontend (Port 3000)                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Tailwind CSS styling                                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ React Router for SPA navigation                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Chart.js for data visualization                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Framer Motion for animations                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Fetch API for HTTP requests                         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚îÇ HTTP POST /api/detect
                            ‚îÇ (multipart/form-data)
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      SERVER LAYER                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ           Flask Backend (Port 5000)                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ CORS enabled for cross-origin requests             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Blueprint-based route organization                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Image validation & preprocessing                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Model caching & lazy loading                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Error handling & validation                         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚îÇ Load Models & Predict
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ML PIPELINE LAYER                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ  CNN Feature Extractor ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  SVM Classifier         ‚îÇ‚îÇ
‚îÇ  ‚îÇ  (TensorFlow/Keras)    ‚îÇ      ‚îÇ  (Scikit-learn)         ‚îÇ‚îÇ
‚îÇ  ‚îÇ                        ‚îÇ      ‚îÇ                         ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ 4 Conv2D blocks     ‚îÇ      ‚îÇ  ‚Ä¢ RBF kernel           ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ BatchNormalization  ‚îÇ      ‚îÇ  ‚Ä¢ StandardScaler       ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ MaxPooling2D        ‚îÇ      ‚îÇ  ‚Ä¢ Probability output   ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Dropout layers      ‚îÇ      ‚îÇ  ‚Ä¢ Trained on CNN       ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Dense(128) bottleneck      ‚îÇ    features (128-dim)   ‚îÇ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Softmax output      ‚îÇ      ‚îÇ                         ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚îÇ Read/Write
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   ARTIFACTS STORAGE                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Disease Task         ‚îÇ     ‚îÇ  Pesticide Task       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ mango_model.h5     ‚îÇ     ‚îÇ  ‚Ä¢ mango_model.h5     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ svm.pkl            ‚îÇ     ‚îÇ  ‚Ä¢ svm.pkl            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ class_indices.json ‚îÇ     ‚îÇ  ‚Ä¢ class_indices.json ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ history.json       ‚îÇ     ‚îÇ  ‚Ä¢ history.json       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ metrics/           ‚îÇ     ‚îÇ  ‚Ä¢ metrics/           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    - model_comparison ‚îÇ     ‚îÇ    - model_comparison ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow Pipeline

1. **User Upload**: Image selected via drag-drop or file picker
2. **Client Validation**: Check file type (JPG/PNG/WEBP) and size (< 5MB)
3. **API Request**: POST to `/api/detect` with image + task parameter
4. **Server Validation**: Validate image format and content
5. **Preprocessing**: 
   - Convert to RGB (3 channels)
   - Resize to 224√ó224 pixels
   - Normalize pixel values to [0, 1]
   - Add batch dimension (1, 224, 224, 3)
6. **Model Loading**: Lazy load from cache or disk based on task
7. **CNN Inference**: 
   - Forward pass through convolutional layers
   - Extract 128-dimensional feature vector
   - Generate class probabilities
8. **SVM Inference**:
   - Use CNN features as input
   - StandardScaler normalization
   - RBF kernel classification
   - Generate probability estimates
9. **Model Selection**: Choose model with highest validation accuracy
10. **Response Formation**: JSON with prediction, confidence, probabilities
11. **Visualization**: Frontend renders results with charts and animations

---

## üìÅ Project Structure

```
mango-pesticide-detector/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ README.md                      # This comprehensive documentation
‚îú‚îÄ‚îÄ üìÑ project_summary.txt            # Technical project summary
‚îú‚îÄ‚îÄ üìÑ .gitignore                     # Git ignore rules
‚îÇ
‚îú‚îÄ‚îÄ üìÇ client/                        # React Frontend Application
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ public/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html                # HTML template
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx                   # Main app with routing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.js                  # React entry point
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ components/            # Reusable components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ClassBadge.jsx        # Disease/pesticide badge
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ HealthBadge.jsx       # API status indicator
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ModelComparisonChart.jsx  # Comparison bar chart
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Navbar.jsx            # Navigation bar
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PerClassBars.jsx      # Confidence visualization
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Upload.jsx            # Image upload UI
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ config/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js                # API endpoints config
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ hooks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useBackendHealth.js   # Health check hook
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ pages/                 # Route pages
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ About.jsx             # About page
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Compare.jsx           # Model comparison
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Home.jsx              # Landing page
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Insights.jsx          # Metrics & matrices
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÇ styles/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ App.css               # Component styles
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ index.css             # Global Tailwind styles
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ package.json                  # npm dependencies
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.js            # Tailwind configuration
‚îÇ   ‚îî‚îÄ‚îÄ postcss.config.js             # PostCSS setup
‚îÇ
‚îú‚îÄ‚îÄ üìÇ server/                        # Flask Backend Application
‚îÇ   ‚îú‚îÄ‚îÄ app.py                        # Main Flask app entry
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ detect.py                 # API endpoints
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ model/                     # ML training & artifacts
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ model_trainer.py          # Standard CNN training
‚îÇ       ‚îú‚îÄ‚îÄ model_trainer_advanced.py # Transfer learning
‚îÇ       ‚îú‚îÄ‚îÄ compare_models.py         # SVM training & comparison
‚îÇ       ‚îú‚îÄ‚îÄ evaluate.py               # Evaluation utilities
‚îÇ       ‚îú‚îÄ‚îÄ generate_dummy_dataset.py # Synthetic data
‚îÇ       ‚îî‚îÄ‚îÄ update_report.py          # Report generation
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ üìÇ artifacts/             # Model storage
‚îÇ           ‚îú‚îÄ‚îÄ üìÇ disease/
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ mango_model.h5    # CNN (81.5% acc)
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ best_model.json   # Model selector
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ class_indices.json
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ history.json
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ training_curves.png
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ models/
‚îÇ           ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ svm.pkl       # SVM classifier
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ üìÇ metrics/
‚îÇ           ‚îÇ       ‚îî‚îÄ‚îÄ model_comparison.json
‚îÇ           ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ üìÇ pesticide/
‚îÇ               ‚îú‚îÄ‚îÄ mango_model.h5    # CNN (97.1% acc)
‚îÇ               ‚îú‚îÄ‚îÄ best_model.json
‚îÇ               ‚îú‚îÄ‚îÄ class_indices.json
‚îÇ               ‚îú‚îÄ‚îÄ history.json
‚îÇ               ‚îú‚îÄ‚îÄ training_curves.png
‚îÇ               ‚îú‚îÄ‚îÄ üìÇ models/
‚îÇ               ‚îÇ   ‚îî‚îÄ‚îÄ svm.pkl
‚îÇ               ‚îî‚îÄ‚îÄ üìÇ metrics/
‚îÇ                   ‚îî‚îÄ‚îÄ model_comparison.json
‚îÇ
‚îî‚îÄ‚îÄ üìÇ datasets/                      # Training data (not in repo)
    ‚îú‚îÄ‚îÄ üìÇ disease/
    ‚îÇ   ‚îî‚îÄ‚îÄ MangoFruitDDS/
    ‚îÇ       ‚îî‚îÄ‚îÄ SenMangoFruitDDS_original/
    ‚îÇ           ‚îú‚îÄ‚îÄ Alternaria/       # ~1000 images
    ‚îÇ           ‚îú‚îÄ‚îÄ Anthracnose/      # ~1000 images
    ‚îÇ           ‚îú‚îÄ‚îÄ Black Mould Rot/  # ~1000 images
    ‚îÇ           ‚îú‚îÄ‚îÄ Healthy/          # ~1000 images
    ‚îÇ           ‚îî‚îÄ‚îÄ Stem end Rot/     # ~1000 images
    ‚îÇ
    ‚îî‚îÄ‚îÄ üìÇ pesticide/
        ‚îú‚îÄ‚îÄ organic/                  # Organic samples
        ‚îî‚îÄ‚îÄ pesticide/                # Treated samples
```

---

## üöÄ Installation

### Prerequisites

Before starting, ensure you have:

- ‚úÖ **Python 3.11+** ([Download](https://www.python.org/downloads/))
- ‚úÖ **Node.js 16+** and **npm** ([Download](https://nodejs.org/))
- ‚úÖ **Git** ([Download](https://git-scm.com/))
- ‚úÖ **8GB+ RAM** (recommended for model training)
- ‚úÖ **GPU with CUDA** (optional, speeds up training 4-5x)

### Step 1: Clone Repository

```bash
git clone https://github.com/rakeshjayanna/final-year-project-.git
cd mango-pesticide-detector
```

### Step 2: Backend Setup

```bash
# Navigate to server directory
cd server

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt
```

**What gets installed:**
- Flask 3.0.0 - Web framework
- TensorFlow 2.18.1 - Deep learning (700MB+)
- NumPy 1.26.2 - Array operations
- Pillow 10.1.0 - Image processing
- Scikit-learn 1.3.2 - ML algorithms
- Flask-CORS 4.0.0 - CORS support
- Matplotlib 3.8.2 - Visualization
- Seaborn 0.13.0 - Statistical plots
- Joblib 1.3.2 - Model persistence
- Gunicorn 21.2.0 - Production server

### Step 3: Frontend Setup

```bash
# Navigate to client directory (from project root)
cd client

# Install Node.js dependencies
npm install
```

**What gets installed:**
- React & React DOM 18.2.0 - UI framework
- React Router DOM 6.26.2 - Routing
- Tailwind CSS 3.4.14 - Styling
- Chart.js 4.4.4 - Charting
- react-chartjs-2 5.2.0 - React charts
- Framer Motion 11.3.24 - Animations
- PostCSS & Autoprefixer - CSS processing

**Installation time:** ~5-10 minutes depending on internet speed

---

## üéì Model Training

### Dataset Preparation

#### Disease Detection Dataset
- **Location**: `datasets/disease/MangoFruitDDS/SenMangoFruitDDS_original/`
- **Structure**: 5 subdirectories (one per class)
- **Total images**: 5000 (1000 per class)
- **Format**: JPG/PNG
- **Recommended size**: 224√ó224 or larger

#### Pesticide Detection Dataset
- **Location**: `datasets/pesticide/`
- **Structure**: 2 subdirectories (`organic/` and `pesticide/`)
- **Total images**: 1035+ recommended
- **Format**: JPG/PNG
- **Balance**: Roughly equal samples per class

### Training Commands

**Option 1: Standard CNN Training (Faster, ~15 minutes)**

```bash
# Disease detection (from project root)
python server/model/model_trainer.py --task disease --epochs 15 --batch-size 32

# Pesticide detection
python server/model/model_trainer.py --task pesticide --epochs 15 --batch-size 32
```

**Option 2: Transfer Learning (Higher Accuracy, ~30 minutes)**

```bash
# Disease with MobileNetV2
python server/model/model_trainer_advanced.py --task disease --epochs 30

# Pesticide with MobileNetV2
python server/model/model_trainer_advanced.py --task pesticide --epochs 30
```

**Training Parameters:**
- `--task`: Either `disease` or `pesticide` (required)
- `--epochs`: Number of training iterations (15-30 recommended)
- `--batch-size`: Images per batch (32 for 8GB RAM, 16 for 4GB)
- `--img-size`: Input dimensions (default: 224 224)
- `--learning-rate`: Initial learning rate (default: 1e-3)
- `--data-dir`: Custom dataset path (optional, auto-detected)

### Model Comparison & SVM Training

After training CNN, generate metrics:

```bash
# Disease task
python server/model/compare_models.py --task disease

# Pesticide task
python server/model/compare_models.py --task pesticide
```

**What this does:**
1. Loads trained CNN model
2. Extracts 128-dimensional features from Dense layer
3. Trains SVM classifier on these features
4. Evaluates both models on validation set (20% of data)
5. Compares accuracies and selects best model
6. Saves comparison metrics to JSON
7. Saves trained SVM to `.pkl` file

### Training Output

After successful training:

```
server/model/artifacts/<task>/
‚îú‚îÄ‚îÄ mango_model.h5              # Trained CNN (~40-50 MB)
‚îú‚îÄ‚îÄ best_model.json             # {"best_model": "svm"}
‚îú‚îÄ‚îÄ class_indices.json          # Label mappings
‚îú‚îÄ‚îÄ history.json                # Training metrics per epoch
‚îú‚îÄ‚îÄ training_curves.png         # Loss/accuracy plots
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ svm.pkl                 # Trained SVM (~1-5 MB)
‚îî‚îÄ‚îÄ metrics/
    ‚îî‚îÄ‚îÄ model_comparison.json   # Detailed comparison
```

**Expected training times (CPU):**
- Disease: ~12-15 minutes (5000 images, 15 epochs)
- Pesticide: ~8-10 minutes (1035 images, 15 epochs)
- With GPU: 3-4x faster

---

## üéÆ Usage

### Development Mode

**Terminal 1 - Backend:**
```bash
cd server
# Activate venv if not already
venv\Scripts\activate  # Windows
# source venv/bin/activate  # macOS/Linux

python app.py
# ‚úì Server runs on http://localhost:5000
```

**Terminal 2 - Frontend:**
```bash
cd client
npm start
# ‚úì Opens browser at http://localhost:3000
```

### Production Mode

**Backend (Gunicorn):**
```bash
cd server
gunicorn --workers 4 --bind 0.0.0.0:5000 --timeout 120 app:app
```

**Frontend (Build & Serve):**
```bash
cd client
npm run build
# Serve build/ directory with nginx, Apache, or other web server
```

### Using the Application

1. **Open** http://localhost:3000 in your browser
2. **Select Analysis Type**:
   - Click "ü¶† Disease Detection" for disease classification
   - Click "üß™ Pesticide Detection" for pesticide analysis
3. **Upload Image**:
   - Click "Upload Mango Image" button
   - OR drag & drop image onto preview area
   - Supported: JPG, PNG, WEBP (max 5MB)
4. **View Results**:
   - Predicted class badge
   - Confidence percentage (0-100%)
   - Per-class probability distribution
   - Model used (SVM or CNN)
5. **Explore More**:
   - Click "Compare" to see model comparison charts
   - Click "Insights" for confusion matrices and metrics
   - Click "About" for project information

---

## üì° API Documentation

### Base URL
```
http://localhost:5000/api
```

### Endpoints

#### 1. Health Check
```http
GET /api/health?task=disease
```

**Query Parameters:**
- `task` (optional): `disease` or `pesticide` (default: `disease`)

**Response (200 OK):**
```json
{
  "status": "ok",
  "task": "disease",
  "model_present": true,
  "best_model": "svm"
}
```

#### 2. Detect/Predict
```http
POST /api/detect
Content-Type: multipart/form-data
```

**Form Data:**
- `image`: Image file (required)
- `task`: `disease` or `pesticide` (required)

**Success Response (200 OK):**
```json
{
  "label": "Healthy",
  "confidence": 91.5,
  "model_used": "svm",
  "task": "disease",
  "models": {
    "cnn": {
      "label": "Healthy",
      "confidence": 89.2,
      "probs": {
        "Alternaria": 2.1,
        "Anthracnose": 3.4,
        "Black Mould Rot": 1.8,
        "Healthy": 89.2,
        "Stem end Rot": 3.5
      }
    },
    "svm": {
      "label": "Healthy",
      "confidence": 91.5,
      "probs": {
        "Alternaria": 1.5,
        "Anthracnose": 2.8,
        "Black Mould Rot": 1.2,
        "Healthy": 91.5,
        "Stem end Rot": 3.0
      }
    }
  },
  "selection": {
    "model": "svm",
    "reason": "highest validation accuracy",
    "detail": {
      "cnn_acc": 0.81,
      "svm_acc": 0.815
    }
  }
}
```

**Error Response (400 Bad Request):**
```json
{
  "error": "Low confidence (45.2%) - image may not be a mango",
  "is_mango": false
}
```

#### 3. Compare Image
```http
POST /api/compare-image
Content-Type: multipart/form-data
```

**Form Data:** Same as `/detect`

**Response:** Includes full comparison details without "final" selection

#### 4. Model Comparison Metrics
```http
GET /api/models/comparison?task=disease
```

**Response (200 OK):**
```json
{
  "models": {
    "cnn": {
      "accuracy": 0.81,
      "report": {
        "0": {
          "precision": 0.647,
          "recall": 0.564,
          "f1-score": 0.603,
          "support": 179
        },
        ...
      },
      "confusion_matrix": [[101, 2, 66, 10, 0], ...]
    },
    "svm": {
      "accuracy": 0.815,
      "report": {...},
      "confusion_matrix": [...]
    },
    "class_names": ["Alternaria", "Anthracnose", ...]
  },
  "best": {
    "name": "svm",
    "accuracy": 0.815
  }
}
```

#### 5. Reload Models
```http
POST /api/reload
Content-Type: application/json
```

**Body (optional):**
```json
{
  "task": "disease"
}
```

**Response (200 OK):**
```json
{
  "status": "reloaded",
  "task": "disease",
  "model_present": true
}
```

---

## üìä Performance Metrics

### Disease Detection Results

**Model Comparison:**
| Model | Accuracy | Precision | Recall | F1-Score | Inference Time |
|-------|----------|-----------|--------|----------|----------------|
| CNN | 81.0% | 81.5% | 81.0% | 81.0% | ~150ms |
| **SVM** | **81.5%** | **82.1%** | **81.5%** | **81.7%** | ~50ms |

**Per-Class Performance (SVM - Best Model):**
| Disease Class | Precision | Recall | F1-Score | Support |
|---------------|-----------|--------|----------|---------|
| Alternaria | 60.3% | 65.4% | 62.7% | 179 |
| Anthracnose | 95.9% | 83.8% | 89.4% | 197 |
| Black Mould Rot | 66.2% | 66.2% | 66.2% | 201 |
| Healthy | 89.4% | 97.1% | 93.1% | 208 |
| Stem end Rot | 95.7% | 92.1% | 93.8% | 215 |

**Key Insights:**
- ‚úÖ **Healthy** mangoes: 97.1% recall (very few missed)
- ‚úÖ **Stem end Rot**: 95.7% precision (reliable diagnosis)
- ‚ö†Ô∏è **Alternaria** vs **Black Mould Rot**: Similar visual features cause confusion
- ‚úÖ Overall: 815 correct predictions out of 1000 test images

### Pesticide Detection Results

**Model Comparison:**
| Model | Accuracy | Precision | Recall | F1-Score | Inference Time |
|-------|----------|-----------|--------|----------|----------------|
| CNN | 45.4% | 45.4% | 45.4% | 45.4% | ~150ms |
| **SVM** | **97.1%** | **97.3%** | **97.1%** | **97.1%** | ~50ms |

**Per-Class Performance (SVM):**
| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Organic | 100.0% | 94.7% | 97.3% | 113 |
| Pesticide | 94.0% | 100.0% | 96.9% | 94 |

**Key Insights:**
- ‚úÖ **SVM dominates**: 97.1% vs 45.4% CNN accuracy
- ‚úÖ **Zero false negatives** for pesticide detection (critical for food safety)
- ‚úÖ **High precision** on both classes
- ‚ÑπÔ∏è CNN struggles with binary classification on this dataset
- ‚úÖ SVM leverages CNN features effectively

### Training Performance

**Disease Model (15 epochs):**
- Training accuracy: 83.3%
- Validation accuracy: 81.5%
- Training time: ~12 min (CPU) / ~3 min (GPU)
- Best epoch: 11 (early stopping)
- Parameters: 423,877 trainable

**Pesticide Model (15 epochs):**
- Training accuracy: 97.7%
- Validation accuracy: 98.1%
- Training time: ~8 min (CPU) / ~2 min (GPU)
- Best epoch: 2 (rapid convergence)
- Parameters: 423,361 trainable

---

## üì∏ Screenshots

### Home Page with Upload
![Home Page](https://via.placeholder.com/1000x600/F59E0B/FFFFFF?text=Home+Page+-+Task+Selection+%26+Upload)

**Features shown:**
- Task selection cards (Disease / Pesticide)
- Drag & drop upload zone
- Image preview
- Live backend status

### Prediction Results
![Results](https://via.placeholder.com/1000x600/16A34A/FFFFFF?text=Prediction+Results+-+Confidence+%26+Probabilities)

**Features shown:**
- Predicted class badge
- Confidence percentage
- Per-class probability bars
- Model used indicator

### Model Comparison
![Comparison](https://via.placeholder.com/1000x600/3B82F6/FFFFFF?text=Model+Comparison+-+CNN+vs+SVM+Accuracy)

**Features shown:**
- Bar chart with accuracies
- Best model indicator
- Task selector

### Insights & Metrics
![Insights](https://via.placeholder.com/1000x600/8B5CF6/FFFFFF?text=Insights+-+Confusion+Matrix+%26+Metrics)

**Features shown:**
- Confusion matrix heatmap
- Per-class metrics table
- Model selector dropdown

---

## üöÄ Deployment

### Docker Deployment

**Backend Dockerfile:**
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .
EXPOSE 5000

CMD ["gunicorn", "--workers", "4", "--bind", "0.0.0.0:5000", "--timeout", "120", "app:app"]
```

**Frontend Dockerfile:**
```dockerfile
FROM node:18-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=build /app/build /usr/share/nginx/html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

**Docker Compose:**
```yaml
version: '3.8'
services:
  backend:
    build: ./server
    ports:
      - "5000:5000"
    volumes:
      - ./server/model/artifacts:/app/model/artifacts
    environment:
      - FLASK_ENV=production
  
  frontend:
    build: ./client
    ports:
      - "80:80"
    depends_on:
      - backend
```

**Run:** `docker-compose up -d`

### Cloud Platforms

**Heroku:**
```bash
# Backend
cd server
heroku create mango-api
heroku git:remote -a mango-api
git push heroku main

# Frontend
cd client
npm run build
# Deploy to Netlify/Vercel/Heroku
```

**AWS EC2:**
1. Launch t2.medium instance (Ubuntu 22.04)
2. Install Python 3.11, Node.js 18
3. Clone repo and follow installation
4. Configure nginx as reverse proxy
5. Setup SSL with Let's Encrypt

**Google Cloud Run:**
```bash
gcloud builds submit --tag gcr.io/PROJECT_ID/mango-detector
gcloud run deploy --image gcr.io/PROJECT_ID/mango-detector --platform managed
```

---

## üêõ Troubleshooting

### Common Issues

**1. "Model not found" error**
```
‚úì Solution: Train models first
python server/model/model_trainer.py --task disease --epochs 15
python server/model/compare_models.py --task disease
```

**2. CORS errors in browser**
```
‚úì Solution: Ensure Flask-CORS installed
pip install flask-cors

‚úì Check app.py has:
CORS(app, resources={r"/api/*": {"origins": "*"}})
```

**3. Out of memory during training**
```
‚úì Solution: Reduce batch size
python server/model/model_trainer.py --batch-size 16 --epochs 15
```

**4. React proxy not working**
```
‚úì Solution: Verify client/package.json has:
"proxy": "http://localhost:5000"

‚úì Restart frontend: npm start
```

**5. TensorFlow warnings**
```
‚úì Solution: Suppress info messages
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
```

**6. Slow predictions**
```
‚úì Solutions:
- Use GPU: Install tensorflow-gpu
- Reduce image size
- Enable model caching (already default)
```

---

## üîÆ Future Enhancements

### Planned Features
- [ ] **Batch image processing** - Upload multiple images at once
- [ ] **Export reports** - Download predictions as PDF/CSV
- [ ] **User authentication** - Login system with prediction history
- [ ] **Real-time camera** - Live detection via webcam
- [ ] **Mobile app** - React Native iOS/Android app
- [ ] **Grad-CAM visualization** - Highlight important image regions
- [ ] **Model versioning** - A/B testing and rollback
- [ ] **Edge deployment** - TensorFlow Lite for offline use
- [ ] **Multi-language UI** - i18n support (Hindi, Spanish, etc.)
- [ ] **RESTful pagination** - For large result sets

### Research Directions
- **Vision Transformers** - Explore ViT/Swin architectures
- **Self-supervised learning** - Reduce labeled data needs
- **Active learning** - Smart sample selection for labeling
- **Ensemble methods** - Combine multiple model predictions
- **Explainable AI** - LIME/SHAP for interpretability

---

## üë• Contributing

We welcome contributions! Please follow:

1. **Fork** the repository
2. **Create branch**: `git checkout -b feature/AmazingFeature`
3. **Commit changes**: `git commit -m 'Add AmazingFeature'`
4. **Push**: `git push origin feature/AmazingFeature`
5. **Open Pull Request**

### Guidelines
- Follow PEP 8 (Python) and ESLint (JavaScript)
- Add tests for new features
- Update documentation
- Keep commits atomic and descriptive

---

## üìÑ License

This project is licensed under the **MIT License** - see [LICENSE](LICENSE) file.

---

## üôè Acknowledgments

- **Dataset**: MangoFruitDDS contributors
- **Frameworks**: TensorFlow, React, Flask, Scikit-learn teams
- **Community**: Stack Overflow, GitHub
- **Advisors**: Academic mentors and reviewers
- **Beta Testers**: For valuable feedback

---

## üìû Contact

**Rakesh Jayanna**
- üíº GitHub: [@rakeshjayanna](https://github.com/rakeshjayanna) 
- üîó LinkedIn: [Rakesh]([https://linkedin.com/in/yourprofile](https://www.linkedin.com/in/rakesh-jayanna-215a3728b/))
- üåê Project: [https://github.com/rakeshjayanna/final-year-project-](https://github.com/rakeshjayanna/final-year-project-)

---

<div align="center">
  <p><strong>Made with ‚ù§Ô∏è for Mango Farmers and Food Safety</strong></p>
  <p>‚≠ê <strong>Star this repo if you find it helpful!</strong></p>
  <p>üîÄ Fork ‚Ä¢ üêõ Report Bug ‚Ä¢ ‚ú® Request Feature</p>
</div>
